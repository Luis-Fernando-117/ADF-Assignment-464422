---
title: "ADF Individual Assignment Report"
author: "Luis F. Barros - 464422"
date: "Last compiled on `r Sys.Date()`"
output: 
    bookdown::html_document2:
        toc: true
        toc_float: 
            collapsed: false
        number_sections: true
        code_folding: hide
        theme: cerulean
editor_options: 
  chunk_output_type: console
---
# Case Description 

## Background: data collection and processing

For this notebook, it is needed to load an R.Data file containing all the raw 
information from Twitter that I got from "collect_data.R" script. 
The output should be another .RData file with the preprocessed data that has the data converted
into data frames ready to analyze.

# Preparation 

Load Libraries 
```{r, message=FALSE }
library("httr")
library("jsonlite")
library("tidyverse")
library("twitteR")
library("rtweet")
library("plyr")
library("dplyr")
library("data.table")
library("tidytext")
library("textdata")
library("udpipe")
library("ggplot2")
```

Load Objects
```{r}
# Followers tweets
  load("text.tweets.obrador.followers.RData")
  load("text.tweets.pinera.followers.RData")
  load("text.tweets.lenin.followers.RData")
  load("text.tweets.bukele.followers.RData")
  
# Presidents Tweets
  load("text.tweets.obrador.RData")
  load("text.tweets.pinera.RData")
  load("text.tweets.lenin.RData")
  load("text.tweets.bukele.RData")
```

# Final Data Preparation (consider moving this to data processing file)
Merge tweets texts into a single data frame
```{r}
text.tweets.obrador.followers$doc_id <- "Obrador_followers"
text.tweets.pinera.followers$doc_id  <- "Pinera_followers"
text.tweets.lenin.followers$doc_id   <- "Lenin_followers"
text.tweets.bukele.followers$doc_id  <- "Bukele_followers"
```

Convert all the tweets text to lowercase
```{r}
text.tweets.obrador.followers$text <- tolower(text.tweets.obrador.followers$text)
text.tweets.pinera.followers$text  <- tolower(text.tweets.pinera.followers$text)
text.tweets.lenin.followers$text   <- tolower(text.tweets.lenin.followers$text)
text.tweets.bukele.followers$text  <- tolower(text.tweets.bukele.followers$text)

```

Calculate the length of each tweets
```{r}
text.tweets.obrador.followers$length <- sapply(strsplit(text.tweets.obrador.followers$text, " "), length)

text.tweets.pinera.followers$length <- sapply(strsplit(text.tweets.pinera.followers$text, " "), length)

text.tweets.lenin.followers$length <- sapply(strsplit(text.tweets.lenin.followers$text, " "), length)

text.tweets.bukele.followers$length <- sapply(strsplit(text.tweets.bukele.followers$text, " "), length)
```

# Data visualization

```{r}
ggplot(text.tweets.obrador.followers) + 
  geom_histogram(aes(x = length), bins = 30)
```



# Text Mining with "Udpipe" package

Define the language of the analysis
```{r}
udmodel <- udpipe_download_model(language = "spanish")
udmodel
```

Deploy the package to tokenise, and tag terms in all the tweets from presidents
followers
```{r}
udmodel.obrador.followers <- udpipe(x = text.tweets.obrador.followers$text, object = udmodel)
udmodel.pinera.followers  <- udpipe(x = text.tweets.pinera.followers$text, object = udmodel)
udmodel.lenin.followers   <- udpipe(x = text.tweets.lenin.followers$text, object = udmodel)
udmodel.bukele.followers  <- udpipe(x = text.tweets.bukele.followers$text, object = udmodel)
```



Filter the dataframes to exclude stopwords, punctuation and symbols
```{r}
rm(udmodel.obrador.followers.filtered, udmodel.pinera.followers.filtered, udmodel.lenin.followers.filtered, udmodel.bukele.followers.filtered)
udmodel.obrador.followers.filtered <- filter(udmodel.obrador.followers, 
                                            (upos != "DET")   & (upos != "SYM") &
                                            (upos != "PUNCT") & (upos != "NUM") & 
                                            (upos != "X")     & (upos != "ADP") &
                                            (upos != "CCONJ") & (upos != "PRON")&
                                            (upos != "SCONJ") & (upos != "ADV") &
                                            (upos != "VERB")  & (upos != "PART")&
                                            (upos != "AUX"))

udmodel.pinera.followers.filtered <- filter(udmodel.pinera.followers, 
                                            (upos != "DET")   & (upos != "SYM") &
                                            (upos != "PUNCT") & (upos != "NUM") & 
                                            (upos != "X")     & (upos != "ADP") &
                                            (upos != "CCONJ") & (upos != "PRON")&
                                            (upos != "SCONJ") & (upos != "ADV"))

udmodel.lenin.followers.filtered <- filter(udmodel.lenin.followers, 
                                            (upos != "DET")   & (upos != "SYM") &
                                            (upos != "PUNCT") & (upos != "NUM") & 
                                            (upos != "X")     & (upos != "ADP") &
                                            (upos != "CCONJ") & (upos != "PRON")&
                                            (upos != "SCONJ") & (upos != "ADV"))

udmodel.bukele.followers.filtered <- filter(udmodel.bukele.followers, 
                                            (upos != "DET")   & (upos != "SYM") &
                                            (upos != "PUNCT") & (upos != "NUM") & 
                                            (upos != "X")     & (upos != "ADP") &
                                            (upos != "CCONJ") & (upos != "PRON")&
                                            (upos != "SCONJ") & (upos != "ADV"))
```

Term Frequency
```{r}
term.frequency.obrador.followers <- txt_freq(udmodel.obrador.followers.filtered$token)
```


To check the definitions of the upos categories, check
https://universaldependencies.org/u/pos/index.html



# Term Frequency

-- Remove Stopwords missing

```{r}
# For presidents tweets
  word.count.obrador <- text.tweets.obrador %>% unnest_tokens(word, text)
  word.count.pinera  <- text.tweets.pinera  %>% unnest_tokens(word, text)
  word.count.lenin   <- text.tweets.lenin   %>% unnest_tokens(word, text)
  word.count.bukele  <- text.tweets.bukele  %>% unnest_tokens(word, text)
```

```{r}
# For followers tweets
  word.count.obrador.followers <- text.tweets.obrador.followers %>% unnest_tokens(word, text)
  word.count.pinera.followers  <- text.tweets.pinera.followers  %>% unnest_tokens(word, text)
  word.count.lenin.followers   <- text.tweets.lenin.followers   %>% unnest_tokens(word, text)
  word.count.bukele.followers  <- text.tweets.bukele.followers  %>% unnest_tokens(word, text)
```




Lets take this approach since we avoid having to remove stopwords 


```{r}
# Get some features out of the tmls data frame
average_text_with <- mean(tmls$display_text_width)
average_retweet_count <- mean(tmls$retweet_count)

```

